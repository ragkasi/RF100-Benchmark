{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f9eda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# This cell installs Grounding DINO and its requirements.\n",
    "# Note: You must enable GPU in Colab (Runtime -> Change runtime type -> T4 GPU)\n",
    "\n",
    "import os\n",
    "\n",
    "# Install Grounding DINO from source (Official Repo)\n",
    "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
    "%cd GroundingDINO/\n",
    "!pip install -q .\n",
    "\n",
    "# Install supervision for easy visualization\n",
    "!pip install -q supervision==0.6.0\n",
    "\n",
    "# Download Pre-trained Weights\n",
    "if not os.path.exists(\"weights\"):\n",
    "    os.makedirs(\"weights\")\n",
    "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth -P weights/\n",
    "\n",
    "print(\"Installation and Download Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76301694",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "import supervision as sv\n",
    "\n",
    "# Paths\n",
    "CONFIG_PATH = \"groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "WEIGHTS_PATH = \"weights/groundingdino_swint_ogc.pth\"\n",
    "\n",
    "model = load_model(CONFIG_PATH, WEIGHTS_PATH)\n",
    "print(\"Model Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274484f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_demo(image_path, text_prompt, box_threshold=0.35, text_threshold=0.25):\n",
    "    print(f\"Running inference on: {image_path} with prompt: '{text_prompt}'\")\n",
    "\n",
    "    # Load image\n",
    "    image_source, image = load_image(image_path)\n",
    "\n",
    "    # Predict\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=model,\n",
    "        image=image,\n",
    "        caption=text_prompt,\n",
    "        box_threshold=box_threshold,\n",
    "        text_threshold=text_threshold\n",
    "    )\n",
    "\n",
    "    # Annotate\n",
    "    annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "    \n",
    "    # Display using Matplotlib (Colab doesn't support cv2.imshow)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Prompt: {text_prompt}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14746bf0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# INSTRUCTIONS: \n",
    "# 1. Click the folder icon on the left sidebar.\n",
    "# 2. Drag and drop your 'samples' folder (containing images) there.\n",
    "\n",
    "# Example 1: Aerial\n",
    "if os.path.exists(\"../samples/aerial_demo.jpg\"):\n",
    "    run_demo(\"../samples/aerial_demo.jpg\", \"aerial view of objects\")\n",
    "else:\n",
    "    print(\"Please upload the 'samples' folder to the Colab runtime!\")\n",
    "\n",
    "# Example 2: Video Game\n",
    "if os.path.exists(\"../samples/game_demo.jpg\"):\n",
    "    run_demo(\"../samples/game_demo.jpg\", \"character, weapon\")\n",
    "\n",
    "# Example 3: Medical (Showing failure/success)\n",
    "if os.path.exists(\"../samples/medical_demo.jpg\"):\n",
    "    run_demo(\"../samples/medical_demo.jpg\", \"x-ray, bone\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
